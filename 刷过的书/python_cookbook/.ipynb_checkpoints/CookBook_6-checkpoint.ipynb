{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章:数据编码和处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 读写CSV数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：读写csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解：csv库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '0.12', '104800']\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    header = next(f_csv)\n",
    "    for row in f_csv: # type(row) == list\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Change</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>39.48</td>\n",
       "      <td>6/11/2007</td>\n",
       "      <td>9:36am</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIG</td>\n",
       "      <td>71.38</td>\n",
       "      <td>6/11/2007</td>\n",
       "      <td>9:36am</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXP</td>\n",
       "      <td>62.58</td>\n",
       "      <td>6/11/2007</td>\n",
       "      <td>9:36am</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA</td>\n",
       "      <td>98.31</td>\n",
       "      <td>6/11/2007</td>\n",
       "      <td>9:36am</td>\n",
       "      <td>0.12</td>\n",
       "      <td>104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>53.08</td>\n",
       "      <td>6/11/2007</td>\n",
       "      <td>9:36am</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAT</td>\n",
       "      <td>78.29</td>\n",
       "      <td>6/11/2007</td>\n",
       "      <td>9:36am</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>225400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol  Price       Date    Time  Change  Volume\n",
       "0     AA  39.48  6/11/2007  9:36am   -0.18  181800\n",
       "1    AIG  71.38  6/11/2007  9:36am   -0.15  195500\n",
       "2    AXP  62.58  6/11/2007  9:36am   -0.46  935000\n",
       "3     BA  98.31  6/11/2007  9:36am    0.12  104800\n",
       "4      C  53.08  6/11/2007  9:36am   -0.25  360900\n",
       "5    CAT  78.29  6/11/2007  9:36am   -0.23  225400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('stocks.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
=======
   "execution_count": 24,
>>>>>>> 714b279adde318b13e0ee614538884f95d673c6c
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
      "row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "39.48\n",
      "row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "71.38\n",
      "row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "62.58\n",
      "row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='0.12', Volume='104800')\n",
      "98.31\n",
      "row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "53.08\n",
      "row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n",
      "78.29\n"
     ]
    }
   ],
   "source": [
    "#为了访问某个字段，需要使用下标，如果row0访问symbol，row4访问change\n",
    "#避免混淆，考虑使用命名元组\n",
    "#坑1：不要使用与模块相同的变量名字\n",
    "#坑2：命名元组不支持字符串里有空格\n",
    "#坑3：命名元组的用法忘了\n",
<<<<<<< HEAD
    "#k4：*r\n",
    "\n",
    "import csv\n",
    "\n",
=======
>>>>>>> 714b279adde318b13e0ee614538884f95d673c6c
    "from collections import namedtuple\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    h_csv = csv.reader(f)\n",
    "    headings = next(h_csv)\n",
    "    print(headings)\n",
    "    row = namedtuple('row', headings)\n",
    "    for r in h_csv:\n",
    "        row_namedtuple = row(*r)\n",
<<<<<<< HEAD
    "        #row_namedtuple = row((i for i in r))\n",
    "        print(row_namedtuple)\n",
    "        print(row_namedtuple.Price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
    "        print(row_namedtuple)\n",
    "        print(row_namedtuple.Price)\n",
    "        \n",
>>>>>>> 714b279adde318b13e0ee614538884f95d673c6c
    "#坑3\n",
    "\n",
    "import re\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv)] # re.sub\n",
    "    row = namedtuple('row', headers)\n",
    "    for r in f_csv:\n",
    "        row = row(*r)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
      "AA\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', '71.38'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.15'), ('Volume', '195500')])\n",
      "AIG\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', '62.58'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.46'), ('Volume', '935000')])\n",
      "AXP\n",
      "OrderedDict([('Symbol', 'BA'), ('Price', '98.31'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '0.12'), ('Volume', '104800')])\n",
      "BA\n",
      "OrderedDict([('Symbol', 'C'), ('Price', '53.08'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.25'), ('Volume', '360900')])\n",
      "C\n",
      "OrderedDict([('Symbol', 'CAT'), ('Price', '78.29'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.23'), ('Volume', '225400')])\n",
      "CAT\n"
     ]
    }
   ],
   "source": [
    "# 将数据写到字典去\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(row['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写入csv数据，使用csv模块，需要先创建一个writer对象\n",
    "#坑1：writerow[] writerow[(), (), ()]\n",
    "#坑2：写csv时，加入newline，避免出现每两行之间出现一个空格\n",
    "#坑3：写文件时，window系统应该把要写的文件关系，不然会出现 权限否定\n",
    "headers = ['Symbol','Price','Date','Time','Change','Volume'] \n",
    "rows= [\n",
    "    ('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "    ('AIG', 71.38,'6/11/2007', '9:36am',-0.15, 195500), \n",
    "    ('AXP', 62.58,'6/11/2007', '9:36am',-0.46, 935000), ]\n",
    "\n",
    "with open('stocks_write.csv', 'w', newline='') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果你有一个字典序列的数据\n",
    "\n",
    "headers = ['Symbol', 'Price', 'Date', 'Time','Change', 'Volume'] \n",
    "rows= [\n",
    "    {'Symbol':'AA','Price':39.48, 'Date':'6/11/2007', 'Time':'9:36am','Change':-0.18, 'Volume':181800}, \n",
    "    {'Symbol':'AIG','Price': 71.38, 'Date':'6/11/2007', 'Time':'9:36am','Change':-0.15, 'Volume': 195500}, \n",
    "    {'Symbol':'AXP','Price': 62.58, 'Date':'6/11/2007', 'Time':'9:36am','Change':-0.46, 'Volume': 935000}, \n",
    "]\n",
    "\n",
    "with open('stocks_writedict.csv', 'w+', newline='') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']\n",
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800\\n']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500\\n']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000\\n']\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '0.12', '104800\\n']\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900\\n']\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400\\n']\n"
     ]
    }
   ],
   "source": [
    "#应该总是优选csv模块分割或解析csv数据\n",
    "#通常也可以使用如下解析csv，但如果碰到字段值被引号保卫，你不得不去除这些引号，其次如果中间还有一个逗号，尴尬\n",
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv库可识别excel使用的csv编码规则，带来很好的兼容性，分隔字符，例如<Tab>\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv产生的数据都是字符串类型的，它不会做任何类型的转换，如果需要转换，必须手动转换\n",
    "\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    header = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row)) # str(values),float(values),int(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接上，转换字典中特定字段的例子\n",
    "\n",
    "print('Reading as dicts with type conversion')\n",
    "field_types = [\n",
    "    ('Price', float),\n",
    "    ('Change', float),\n",
    "    ('Volume', int)\n",
    "]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        #row=OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
    "        row.update(\n",
    "            (key, conversion(row[key])) for key, conversion in field_types # 'Price',float(row['Price'])\n",
    "        )\n",
    "        print(row)\n",
    "\n",
    "#实际情况，csv文件都或多或少有些缺失数据，格式不规范的数据，转换步骤通常都是存在的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 读写JSON数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：读json数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解：json模块提供了json dumps 和 json loads函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# python -> json\n",
    "data = {\n",
    "    'name' : 'ACME',\n",
    "    'shares' : 100,\n",
    "    'price' : 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json -> python\n",
    "\n",
    "data = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果你要处理的是文件而不是字符串，你可以使用json dump，json load来编码和解码json数据\n",
    "\n",
    "# Writing JSON data \n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "# Reading data back\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#json编码支持的基本数据类型 None bool int float str，以及包含这些类型数据的list tuple dictionaries\n",
    "#对于dictionaries，keys需要是字符串类型\n",
    "#为了遵循json规范，你应该只编码python的lists和dictionaries\n",
    "#web程序中，顶层对象呗编码为一个字典是一个标准做法\n",
    "#python-json True-true False-false None -null\n",
    "\n",
    "json.dumps(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'a' : True, \n",
    "    'b' : 'Hello', \n",
    "    'c' : None\n",
    "}\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当你检查json解码后的数据，你通常很难通过简单的打印来确定他的结构\n",
    "#特别是当数据的嵌套结构层次很深或包含大量的字段时，为了解决这个问题，可以考虑使用pprint代替print\n",
    "#它会按照key的字母顺序并以一种更加美观的方式输出\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "\n",
    "u= urlopen('http://search.twitter.com/search.json?q=python&rpp=5') # Not found\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n"
     ]
    }
   ],
   "source": [
    "#一般来讲，json解码会根据提供的数据创建dicts 或者 lists，如果你想要创建其他类型的对象，可以给json.loads()传递\n",
    "#object_paris_hook, object_hook参数\n",
    "#例子：json数据并在OrderedDict中保留其顺序的例子\n",
    "#坑1：s是字符串\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "s = '{\"name\" : \"ACME\", \"shares\" : 50 , \"price\": 490.1}'\n",
    "data = json.loads(s , object_pairs_hook=OrderedDict)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ACME', 50, 490.1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json dict -> python obj\n",
    "\n",
    "class JSONObject: # ?\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "data = json.loads(s, object_hook=JSONObject)\n",
    "data.name, data.shares, data.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.JSONObject object at 0x0000020EA18C6978>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}\n"
     ]
    }
   ],
   "source": [
    "# 在编码JSON的时候，还有一些选项很有用，如果你想获得漂亮的格式化字符串后输出，可以使用json.dumps()的indent函数\n",
    "# 它和pprint有类似的效果\n",
    "\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 50,\n",
      "    \"price\": 490.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'Point' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-962baafc111f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ssoftware\\anaconda\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ssoftware\\anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ssoftware\\anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32mD:\\ssoftware\\anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'Point' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# 对象实例通常并不是JSON可序列化的\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "p = Point(2, 3)\n",
    "json.dumps(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个可序列化的字典\n",
    "# ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 解析简单的XML数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：从简单的XML中提取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决：xml.etree.ElementTree模块从简单xml文档中提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import parse # 解析整个xml文档并将其转换成一个文档对象\n",
    "\n",
    "doc = parse('rss2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SteveHolden: Python forData Analysis\n",
      "None\n",
      "http://holdenweb.blogspot.com/...-data-analysis.html\n",
      "----------------------------------------------------------------------\n",
      "VasudevRam: The Python Data model (for v2 and v3)\n",
      "None\n",
      "http://jugad2.blogspot.com/...-data-model.html\n",
      "----------------------------------------------------------------------\n",
      "Python Diary: Been playingaround with Object Databases\n",
      "None\n",
      "http://www.pythondiary.com/...-object-databases.html\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 必须对xml的标签有个了解\n",
    "\n",
    "for item in doc.iterfind('channel/item'): # Xpath\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubData')\n",
    "    link = item.findtext('link')\n",
    "    \n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print('-' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x1e998fb2860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('title', 'Planet Python', None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e.tag, e.text, e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于更高级的程序，你需要考虑使用lxml，它使用与元素树同样的编程接口，因为上面的例子同样也适用于lxml\n",
    "# 速度快，支持验证，XSLT，XPath\n",
    "from lxml.etree import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 增量式解析大型的XML文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：你想使用尽可能少的内存从一个超大的XML文档中提取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决：任何时候只要遇到增量式的数据处理时，就应该想到迭代器和生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#事件start：某个元素第一次被创建并且还没有被插入其他数据时被创建\n",
    "#事件end：某个元素已经完成时被创建\n",
    "#事件start-ns，end-ns事件被用来处理XML文档命名空间的声明\n",
    "#本例中，start & end 用来管理元素和标签栈\n",
    "#栈代表了文档被解析时的层次结构，还没用来判断某个元素是否匹配传给函数parse and remove的路径\n",
    "#如果匹配，就利用yield语句想调用者返回这个元素\n",
    "\n",
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end')) # 允许对xml文档进行增量从操作 ，一种或多种类型的事件列表start, end, start-ns, end-ns,return (event, elem)\n",
    "    next(doc) # skip head element\n",
    "    \n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem) # 使得程序占用极少内存的elementTree的核心特性，使之前有yield产生的元素从它的父节点中删除掉，没有引用，回收内存\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用超过100000行数据的xml\n",
    "# 内存占用450M内存\n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "    \n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内存占用7M的内存\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "    \n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 将字典转为XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= { 'name': 'GOOG', 'shares': 100, 'price':490.1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stock' at 0x000001E9999B1188>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = dict_to_xml('stock', s)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换结果时一个Element实例，对于IO操作，使用 tostring函数很容易就能将它转换一个字节字符串\n",
    "from xml.etree.ElementTree import tostring\n",
    "\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'<stock _id=\"1234\"><name>GOOG</name><shares>100</shares><price>490.1</price><'\n",
      " b'/stock>')\n"
     ]
    }
   ],
   "source": [
    "# 如果你想给某个元素添加属性值\n",
    "from pprint import pprint\n",
    "\n",
    "e.set('_id', '1234')\n",
    "tostring(e)\n",
    "pprint(tostring(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当创建XML的时候，你被限制只能构造字符串类型的值\n",
    "\n",
    "def dict_to_xml_str(tag, d):\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key, val))\n",
    "    parts.append('</{}>'.format(tag))\n",
    "    return ''.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<item><name><spam></name></item>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手动的去构造的时候可能会遇到一些麻烦，例如，当字典的值包含一些特殊字符的时候\n",
    "\n",
    "d = {'name' : '<spam>'}\n",
    "dict_to_xml_str('item', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<item><name>&lt;spam&gt;</name></item>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = dict_to_xml('item', d)\n",
    "tostring(e) # <> -> &lt &gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果需要手动去转换这些字符，可以使用xml.sax.saxutils中的escape和unescape函数\n",
    "# 推荐创建elemet而不是字符串\n",
    "from xml.sax.saxutils import escape, unescape\n",
    "\n",
    "escape('<spam>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<spam>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unescape(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 解析和修改XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 利用命名空间解析XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 与关系数据库的交互"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：你想在关系型数据库中查询、增加、删除记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决：pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.9 编码和解码十六进制数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：你想将一个十六进制字符串解码成一个字节字符串或者将一个字节字符串编码成一个十六进制字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解：如果你只是简单的解码或编码一个十六进制的原始字符串，可以使用binascii模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656c6c6f'\n"
     ]
    }
   ],
   "source": [
    "#坑1：忘了b'str'是啥了\n",
    "\n",
    "import binascii\n",
    "\n",
    "# Initial Byte string\n",
    "s = b'hello'\n",
    "# Encode as hex\n",
    "h = binascii.b2a_hex(s)\n",
    "print(h) # 十六进制的字符串还是十六进制的字节字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decode back to bytes\n",
    "binascii.a2b_hex(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656C6C6F'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#类似的功能，不同的模块\n",
    "import base64\n",
    "\n",
    "s = b'hello'\n",
    "h = base64.b16encode(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b16decode(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656C6C6F'\n"
     ]
    }
   ],
   "source": [
    "#注意\n",
    "#base64.b16decode base64encode只能操作大写形式的十六进制字母，而binascii模块中的函数大小写都能处理\n",
    "#编码函数总是输出一个字节字符串，如果强制Unicode形式输出，需要额外步骤\n",
    "#在解码十六进制时，b16decode a2b_hex 可以接受字节或者unicode字符串，\n",
    "#但是unicode字符串必须仅仅包含ascii编码的十六进制数\n",
    "h = base64.b16encode(s)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68656C6C6F\n"
     ]
    }
   ],
   "source": [
    "print(h.decode('ascii')) # ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 编码解码Base64数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：你需要使用的Base64格式解码编码二进制数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决方案：base64模块中有两个函数 b64encode b64decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Base64编码仅仅用于面向字节的数据比如字节字符串和字节数组\n",
    "#编码处理的输出结果总是一个字节字符串\n",
    "import base64\n",
    "\n",
    "# Some byte data\n",
    "s = b'hello'\n",
    "\n",
    "#encode as Base64\n",
    "a = base64.b64encode(s)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decode from Base64\n",
    "base64.b64decode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aGVsbG8='"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果你想混合使用Base64编码的数据和UNicode文本，必须添加一个额外步骤\n",
    "#在解码Base64时，可以接受字节或者unicode字符串，\n",
    "#但是unicode字符串必须仅仅包含ascii编码的十六进制数\n",
    "a = base64.b64encode(s).decode('ascii')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.11 读写二进制数组数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：你想读写一个二进制数组的结构化数据到python元组中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决方案：可以使用struct模块处理二进制数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将一个python元组列表写入一个二进制文件，并使用struct将每个元组编码为一个结构体\n",
    "\n",
    "from struct import Struct\n",
    "\n",
    "def write_records(records, format, f):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------------\n",
    "    records : list(tuple, tuple)\n",
    "    format : \n",
    "    f : file I/O\n",
    "    \"\"\"\n",
    "    records_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(records_struct.pack(*r))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    records = [(1, 2.3, 4.5), (6, 7.8, 9.0), (12, 13.4, 56.8)]\n",
    "    with open('data.b', 'wb') as f:\n",
    "        write_records(records, '<idd', f) # <idd  高位在左 int float float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取.B文件并返回一个元组列表，以块的形式增量读取文件\n",
    "\n",
    "from  struct import Struct\n",
    "\n",
    "def read_records(format, f):\n",
    "    records_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(records_struct.size), b'')\n",
    "    return (records_struct.unpack(chunk) for chunk in chunks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open('data.b', 'rb') as f:\n",
    "        for rec in read_records('<idd', f):\n",
    "            pass\n",
    "        \n",
    "#将整个文件读取到一个字节字符串中，然后再分片解析\n",
    "\n",
    "from  struct import Struct\n",
    "\n",
    "def unpack_records(format, f):\n",
    "    records_struct = Struct(format)\n",
    "    return (records_struct.unpack_from(data, offset) for offset in range(0, len(data), records_struct.size))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open('data.b', 'rb') as f:\n",
    "        data = f.read()\n",
    "        for rec in read_records('<idd', data):\n",
    "            pass\n",
    "        \n",
    "#两种情况下的结果都是一个可返回用来创建该文件的原始元组的迭代对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对于需要编码和解码二进制数据程序而言，通常会使用struct模块，声明一个新的结构体\n",
    "\n",
    "record_struct = Struct('<idd')\n",
    "\n",
    "#产生的Struct实例有很多属性和方法用来操作相应类型的机构\n",
    "#size 结构的字节数\n",
    "#pack unpack 打包和解包数据\n",
    "\n",
    "from struct import Struct\n",
    "record_struct = Struct('<idd')\n",
    "record_struct.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.pack(1, 2.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.0, 3.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.unpack(_) # ! 没有引号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00333333\\x07@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pack unpack操作模块级函数被调用\n",
    "\n",
    "import struct\n",
    "struct.pack('<idd', 1, 2.9, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.9, 3.0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.unpack('<idd', _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x20ea3615358>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编程技巧读取二进制结构的代码\n",
    "\n",
    "f = open('data.b', 'rb')\n",
    "chunks = iter(lambda: f.read(20), b'') # lambda 还可以不放参数\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x00\\x00\\x00ffffff\\x02@\\x00\\x00\\x00\\x00\\x00\\x00\\x12@'\n",
      "b'\\x06\\x00\\x00\\x00333333\\x1f@\\x00\\x00\\x00\\x00\\x00\\x00\"@'\n",
      "b'\\x0c\\x00\\x00\\x00\\xcd\\xcc\\xcc\\xcc\\xcc\\xcc*@ffffffL@'\n"
     ]
    }
   ],
   "source": [
    "for chk in chunks:\n",
    "    print(chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无编程技巧\n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    while True:\n",
    "        chk = f.read(record_struct.size)\n",
    "        if chk == b'':\n",
    "            break\n",
    "        yield record_struct.unpack(chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack_from 对于从一个大型二进制数组中提取二进制数据非常有用，它不会产生任何的临时对象或进行内存复制操作\n",
    "# 只需要给它一个字节字符串或数组和一个字节偏移量，它会从那个位置开始直接解包数据\n",
    "\n",
    "#如果你使用unpack来代替unpack from，你需要修改代码来构造大量的小的切片以及进行偏移量的计算\n",
    "# 很复杂\n",
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (record_struct.unpack(data[offset:offset + record_struct.size]) for offset in range(0, len(data), record_struct.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-067dea7c1f60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'kind'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.p'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<idd'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.p'"
     ]
    }
   ],
   "source": [
    "#解包的时候，配合namedtuple\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "record = namedtuple('record', ['kind', 'x', 'y'])\n",
    "\n",
    "with open('data.p' ,'rb') as f:\n",
    "    records = (record(*r) for r in read_records('<idd' ,f))\n",
    "    \n",
    "for r in records:\n",
    "    print(r.kind, r.x, r.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 1,  2.3,  4.5), ( 6,  7.8,  9. ), (12, 13.4, 56.8)],\n",
       "      dtype=[('f0', '<i4'), ('f1', '<f8'), ('f2', '<f8')])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果处理大量的二进制数据，最好numpy模块，将一个二进制数据读取到一个结构化数组中而不是一个元组列表中\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "f = open('data.b', 'rb')\n",
    "records = np.fromfile(f, dtype='<i, <d, <d')\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2.3, 4.5), (6, 7.8, 9.))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0],records[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.12 读取嵌套的可变二进制数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决方案：structmokuai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.13 数据的累加与统计操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#......"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.3"
=======
   "version": "3.6.8"
>>>>>>> 714b279adde318b13e0ee614538884f95d673c6c
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
