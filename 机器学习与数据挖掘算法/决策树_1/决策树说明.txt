决策树说明
优点：计算复杂度不高、输入结果易于理解、对中间值的缺失不敏感、可以处理不相关特征数据

缺点：可能产生过度匹配的问题
适用数据类型：数值型和标称型

决策树进行分类，决策树不断将数据切分成小数据集，直到所有目标变量完全相同，或者数据不能再切分为止
决策树是一种贪心算法，它要在给定时间内做出最佳选择，但并不关心能否达到全局最优

优点：可以对复杂和非线性的数据建模
缺点：结果不易理解？？输出结果不易理解？

ID3算法存在另外一个问题，不能直接连续性特征，只有实现将连续型特征转成离散型，才能在ID3中使用，但这种转换过程会破坏连续型变量的内在特征

二元切分法：进行调整后可以处理连续型特征，其次，也节省了树的构建时间

一般构建树都是离线完成，时间并非需要重点关注的因素

CART：使用二元切分来处理连续型变量
-----------------------------------
1.获得最大信息增益的特征处进行节点划分
2.定义目标函数
3.目标函数能在每次划分时实现对信息增益的最大化
4.IG(Dp,f) = I(Dp)-∑(i=1,inf) Nj/NpI(Dj) 1.1式
f 将要进行划分的特征
Dp Dj 父节点和第j个子节点
I 不纯度衡量标准
Np 父节点中样本的数量
Nj 第j个子节点中样本的数量
信息增益是父节点的不纯度与所有子节点不纯度总和之差————子节点的不纯度越低，信息增益越大
大多数库中实现的都是二叉决策树，意味着每个父节点被划分为两个子节点D(left) D(right)
1.1式 就转换成了：
IG(Dp,f) = I(Dp)- (N(left)/N(p) * I(Dleft)) - (N(right)/N(p) * I(D(right))) 1.2式
------------------------------------
熵 I(G) = -∑(i=1,c)p(i|t)log2 p(i|t)
基尼指数 I(H) = ∑(i=1,c) p(i|t)(-p(i|t)) = 1 - ∑(i=1,c) p(i|t)**2
误差类率 I(E) = 1 - max{p(i|t)} # 这是一个对剪枝很有用的准则，但是不建议用于决策树的构建，\
因为它对各类样本数量的变动不敏感
A情况：
        40，40
30，10         10，30
----------------------
误分类率
Ie(Dp) = 1-0.5 = 0.5

Ie(Dleft) = 1 - 3/4 = 0.25
Ie(Dright) = 1 - 3/4 = 0.25
IGe = 0.5 - 4/8 * 0.25 - 4/8 * 0.25 = 0.25 套1.2式
----------------------
基尼指数
IG(Dp) = 1 - (0.5**2 + 0.5**2) = 0.5
# 每种算法的I(Dp)需要单独计算
IG(Dleft) = 1 - (3/4 **2) - (1/4 **2) = 3/8 = 0.375
IG(Dright) = 1 - (1/4 **2) - (3/4 **2) = 3/8 = 0.375
IGg = 0.5 - 4/8 * 0.375 - 4/8 * 0.375 = 0.125
----------------------
熵
I(Dp) = -(0.5log2 (0.5) - 0.5log2 (0.5)) = 1

IH(Dleft) = -3/4 * log2 (3/4) - 1/4 * log2(1/4) =0.81
IH(Dright) = -1/4 * log2 (1/4) - 3/4 * log2(3/4) =0.81
IGh = 1 - 4/8 * 0.81 - 4/8 * 0.81 = 0.19
-----------------------
-----------------------
B情况：
        40，40
20，20         20，0
----------------------
误分类率
Ie(Dleft) = 1 - 4/6 = 1/3
Ie(Dright) = 1 - 1 = 0
IGe = 0.5-6/8 * 1/3 - 0 = 0.25 套1.2式
----------------------
基尼指数
IG(Dleft) = 1 - (2/6 **2) - (4/6 **2) = 4/9 = 0.4
IG(Dright) = 1 - (1 **2) - (0 **2) = 0
IGg = 0.5 - 6/8 * 0.4 - 2/8 * 0 = 0.16
基尼指数更倾向于使用B(IG=0.16>0.125)的划分
-----------------------
熵
IH(Dleft) = -2/6 * log2 (2/6) - 4/6 * log2 (4/6) =0.92
IH(Dright) = 0 # ? log2 (20/20=1)  = 0 
IGh = 1 - 6/8 * 0.92 - 0 = 0.31
熵 更倾向于使用B(IGh=0.31>0.19)
-----------------------