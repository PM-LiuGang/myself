{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多进程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。\n",
    "\n",
    "子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。\n",
    "\n",
    "Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print('Process (%s) start...' % os.getpid())\n",
    "# Only works on Unix/Linux/Mac:\n",
    "pid = os.fork()\n",
    "if pid == 0:\n",
    "    print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))\n",
    "else:\n",
    "    print('I (%s) just created a child process (%s).' % (os.getpid(), pid))\n",
    "    \n",
    "'''\n",
    "run @ Linux or Unix\n",
    "Process (876) start...\n",
    "I (876) just created a child process (877).\n",
    "I am child process (877) and my parent is 876.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于Windows没有fork调用，上面的代码在Windows上无法运行。由于Mac系统是基于BSD（Unix的一种）内核，所以，在Mac下运行是没有问题的，推荐大家用Mac学Python！\n",
    "\n",
    "有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。\n",
    "\n",
    "multiprocessing\n",
    "如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？\n",
    "\n",
    "由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。\n",
    "\n",
    "multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 13860.\n",
      "Child process will start\n",
      "Child process end.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def run_proc(name):\n",
    "    print('Run child process %s (%s)...' % (name, os.getpid()))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p = Process(target=run_proc, args=('test',))\n",
    "    print('Child process will start')\n",
    "    p.start()\n",
    "    p.join() # join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步\n",
    "    print('Child process end.')\n",
    "\n",
    "'''\n",
    "@window python xxx.py\n",
    "Parent process 1816.\n",
    "Child process will start\n",
    "Run child process test (10072)...\n",
    "Child process end.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son:13860  father:1280\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from multiprocessing import Process\n",
    "\n",
    "def func_one():\n",
    "    print(\"This is son_one\")\n",
    "    print(\"son_one:%s  father:%s\" % (os.getpid(), os.getppid()))\n",
    " \n",
    " \n",
    "def func_two():\n",
    "    print(\"This is son_two\")\n",
    "    print(\"son_two:%s  father:%s\" % (os.getpid(), os.getppid()))\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    p_one = Process(target=func_one)\n",
    "    P_two = Process(target=func_two)\n",
    "    p_one.start()\n",
    "    P_two.start()\n",
    "    print(\"son:%s  father:%s\" % (os.getpid(), os.getppid()))\n",
    "    \n",
    "'''\n",
    "python xxx.py\n",
    "son:5536  father:7300\n",
    "This is son_one\n",
    "This is son_two\n",
    "son_one:4440  father:5536\n",
    "son_two:13252  father:5536\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am main process\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    " \n",
    "def func_one(name):\n",
    "    print(\"My name is\", name)\n",
    "    time.sleep(2)\n",
    "    print(\"This is func_one\")\n",
    " \n",
    " \n",
    "def func_two(name):\n",
    "    print(\"My name is\", name)\n",
    "    time.sleep(2)\n",
    "    print(\"This is func_two\")\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    p_one = Process(target=func_one, args=(\"Jack\",))\n",
    "    p_two = Process(target=func_two, args=(\"Mick\",))\n",
    "    p_one.start()\n",
    "    p_one.join()  # 主线程要等待func_one终止，才继续往下走\n",
    "    p_two.start()\n",
    "    print('I am main process')\n",
    "    \n",
    "    \n",
    "'''\n",
    "My name is Jack\n",
    "This is func_one\n",
    "I am main process\n",
    "My name is Mick\n",
    "This is func_two\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要启动大量的子进程，可以用进程池的方式批量创建子进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os, time, random\n",
    "\n",
    "def long_time_task(name):\n",
    "    print('Run task %s (%s)...' % (name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)\n",
    "    end = time.time()\n",
    "    print('Task %s runs %0.2f seconds.' % (name, (end-start)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print('Parent Process is %s' % os.getpid())\n",
    "    p = Pool(4)\n",
    "    for i in range(5):\n",
    "        p.apply_async(long_time_task, args=(i, )) # p.apply_async  不用等待当前进程执行完毕，随时根据系统调度来进行进程切换 | 异步非阻塞的\n",
    "    print('Waiting for all subprocess done')\n",
    "    p.close() #调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了\n",
    "    p.join()  # 对Pool对象调用join()方法会等待所有子进程执行完毕，\n",
    "    print('All subprocesses done')\n",
    "    \n",
    "'''\n",
    "请注意输出的结果，task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行，这是因为Pool的默认大小在我的电脑上是4\n",
    "因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制\n",
    "p = Pool(5) 就可以同时跑5个进程。\n",
    "由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果\n",
    "\n",
    "Parent Process is 13908\n",
    "Waiting for all subprocess done\n",
    "Run task 0 (2308)...\n",
    "Run task 1 (12892)...\n",
    "Run task 2 (11744)...\n",
    "Run task 3 (12736)...\n",
    "Task 0 runs 1.20 seconds.\n",
    "Run task 4 (2308)...\n",
    "Task 1 runs 1.42 seconds.\n",
    "Task 3 runs 1.74 seconds.\n",
    "Task 4 runs 0.67 seconds.\n",
    "Task 2 runs 1.84 seconds.\n",
    "All subprocesses done\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。\n",
    "\n",
    "subprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。\n",
    "\n",
    "下面的例子演示了如何在Python代码中运行命令nslookup www.python.org，这和命令行直接运行的效果是一样的·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ nslookup www.python.org\n",
      "Exit code: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print('$ nslookup www.python.org')\n",
    "r = subprocess.call(['nslookup','www.python.org'])\n",
    "print('Exit code:', r)\n",
    "'''\n",
    "服务器:  UnKnown\n",
    "Address:  172.168.10.1\n",
    "\n",
    "非权威应答:\n",
    "名称:    dualstack.python.map.fastly.net\n",
    "Addresses:  2a04:4e42:1a::223\n",
    "          151.101.228.223\n",
    "Aliases:  www.python.org\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果子进程还需要输入，则可以通过communicate()方法输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run linux or Unix\n",
    "\n",
    "import subprocess\n",
    "\n",
    "print('$ nslookup')\n",
    "p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "output, err = p.communicate(b'set q=mx\\npython.org\\nexit\\n')\n",
    "print(output.decode('utf-8'))\n",
    "print('Exit code:', p.returncode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码相当于在命令行执行命令nslookup，然后手动输入："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set q=mx\n",
    "\n",
    "python.org\n",
    "\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。\n",
    "\n",
    "我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import os, time, random\n",
    "\n",
    "# 写数据进程执行的代码:\n",
    "def write(q):\n",
    "    print('Process to write: %s' % os.getpid())\n",
    "    for value in ['A', 'B', 'C']:\n",
    "        print('Put %s to queue...' % value)\n",
    "        q.put(value) # q.put?\n",
    "        time.sleep(random.random())\n",
    "\n",
    "# 读数据进程执行的代码:\n",
    "def read(q):\n",
    "    print('Process to read: %s' % os.getpid())\n",
    "    while True:\n",
    "        value = q.get(True) # get(True)\n",
    "        print('Get %s from queue.' % value)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # 父进程创建Queue，并传给各个子进程：\n",
    "    q = Queue()\n",
    "    pw = Process(target=write, args=(q,))\n",
    "    pr = Process(target=read, args=(q,))\n",
    "    # 启动子进程pw，写入:\n",
    "    pw.start()\n",
    "    # 启动子进程pr，读取:\n",
    "    pr.start()\n",
    "    # 等待pw结束:\n",
    "    pw.join()\n",
    "    # pr进程里是死循环，无法等待其结束，只能强行终止:\n",
    "    pr.terminate()\n",
    "    \n",
    "'''\n",
    "Process to write: 1128\n",
    "Put A to queue...\n",
    "Process to read: 12876\n",
    "Get A from queue.\n",
    "Put B to queue...\n",
    "Get B from queue.\n",
    "Put C to queue...\n",
    "Get C from queue.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Unix/Linux下，可以使用fork()调用实现多进程。\n",
    "\n",
    "要实现跨平台的多进程，可以使用multiprocessing模块。\n",
    "\n",
    "进程间通信是通过Queue、Pipes等实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多线程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多任务可以由多进程完成，也可以由一个进程内的多线程完成。\n",
    "\n",
    "我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。\n",
    "\n",
    "由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。\n",
    "\n",
    "Python的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。\n",
    "\n",
    "启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread MainThread is running...\n",
      "thread LoopThread is running....\n",
      "thread LoopThread >>> 1\n",
      "thread LoopThread >>> 2\n",
      "thread LoopThread >>> 3\n",
      "thread LoopThread >>> 4\n",
      "thread LoopThread >>> 5\n",
      "thread LoopThread ended.\n",
      "thread MainThread ended.\n"
     ]
    }
   ],
   "source": [
    "import time, threading\n",
    "\n",
    "def loop():\n",
    "    print('thread %s is running....' % threading.current_thread().name)\n",
    "    n = 0\n",
    "    while n<5:\n",
    "        n = n + 1\n",
    "        print('thread %s >>> %s' % (threading.current_thread().name, n)) # 不多通过循环也能多次打印啊\n",
    "        time.sleep(1)\n",
    "    print('thread %s ended.' % threading.current_thread().name)\n",
    "    \n",
    "print('thread %s is running...' % threading.current_thread().name)\n",
    "t = threading.Thread(target=loop, name='LoopThread')\n",
    "t.start()\n",
    "t.join()\n",
    "print('thread %s ended.' % threading.current_thread().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。\n",
    "\n",
    "来看看多个线程同时操作一个变量怎么把内容给改乱了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import time, threading\n",
    "\n",
    "balance = 0 # 银行存款\n",
    "\n",
    "def change_it(n):\n",
    "    # 先存后去，结果应该是0\n",
    "    global balance \n",
    "    balance = balance + n\n",
    "    balance = balance - n\n",
    "    \n",
    "def run_thread(n):\n",
    "    for i in range(100000):\n",
    "        change_it(n)\n",
    "        \n",
    "t1 = threading.Thread(target=run_thread, args=(5,))\n",
    "t2 = threading.Thread(target=run_thread, args=(8,))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it()，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def run_thread(n):\n",
    "    for i in range(100000):\n",
    "        lock.acquire()\n",
    "    try:\n",
    "        change_it(n)\n",
    "    finally:\n",
    "        lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。\n",
    "\n",
    "获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try...finally来确保锁一定会被释放。\n",
    "\n",
    "锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多核CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你不幸拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。\n",
    "\n",
    "如果写一个死循环的话，会出现什么情况呢？\n",
    "\n",
    "打开Mac OS X的Activity Monitor，或者Windows的Task Manager，都可以监控某个进程的CPU使用率。\n",
    "\n",
    "我们可以监控到一个死循环线程会100%占用一个CPU。\n",
    "\n",
    "如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。\n",
    "\n",
    "要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。\n",
    "\n",
    "试试用Python写个死循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。\n",
    "\n",
    "但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n",
    "\n",
    "因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\n",
    "\n",
    "GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n",
    "\n",
    "所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n",
    "\n",
    "不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。\n",
    "\n",
    "Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThreadLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。\n",
    "\n",
    "但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_student(name):\n",
    "    std = Student()\n",
    "    do_task_1(std)\n",
    "    do_task_2(std)\n",
    "    \n",
    "def do_task_1(std):\n",
    "    do_substask_1(std)\n",
    "    do_substask_2(std)\n",
    "    \n",
    "def do_task_2(std):\n",
    "    do_subtask_2(std)\n",
    "    do_subtask_2(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的Student对象，不能共享。\n",
    "\n",
    "如果用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dict = {}\n",
    "\n",
    "def std_thread(name):\n",
    "    std = Student(name)\n",
    "    global_dict[threading.current_thread()] = std # 把std放到全局变量global_dict中\n",
    "    do_task_1()\n",
    "    do_task_2()\n",
    "\n",
    "def do_task_1():\n",
    "    std = global_dict[threading.current_thread()] # 不传入std，而是根据当前线程查找：\n",
    "    pass\n",
    "    \n",
    "def do_task_2():\n",
    "    std = global_dict[threading.current_thread()] # 任何函数都可以查找出当前线程的std变量：\n",
    "    pass\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Alice (in Thread-A)\n",
      "Hello, Bob (in Thread-B)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "    \n",
    "# 创建全局ThreadLocal对象:\n",
    "local_school = threading.local()\n",
    "\n",
    "def process_student():\n",
    "    # 获取当前线程关联的student:\n",
    "    std = local_school.student\n",
    "    print('Hello, %s (in %s)' % (std, threading.current_thread().name))\n",
    "\n",
    "def process_thread(name):\n",
    "    # 绑定ThreadLocal的student:\n",
    "    local_school.student = name\n",
    "    process_student()\n",
    "\n",
    "t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')\n",
    "t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全局变量local_school就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把local_school看成全局变量，但每个属性如local_school.student都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。\n",
    "\n",
    "可以理解为全局变量local_school是一个dict，不但可以用local_school.student，还可以绑定其他变量，如local_school.teacher等等。\n",
    "\n",
    "ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分布式进程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。\n",
    "\n",
    "Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。\n",
    "\n",
    "举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？\n",
    "\n",
    "原有的Queue可以继续使用，但是，通过managers模块把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了。\n",
    "\n",
    "我们先看服务进程，服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_master.py\n",
    "\n",
    "import random, time, queue\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "task_queue = queue.Queue() # 发送任务的队列:\n",
    "result_queue = queue.Queue() # 接收结果的队列:\n",
    "\n",
    "class QueueManger(BaseManager):\n",
    "    pass\n",
    "\n",
    "# 把两个Queue都注册到网络上, callable参数关联了Queue对象:\n",
    "QueueManger.register('get_task_queue', callable=lambda:task_queue)\n",
    "QueueManger.register('get_task_queue', callable=lambda:result_queue)\n",
    "\n",
    "manager = QueueManger(address=('', 5000), authkey=b'abc') # 绑定端口5000, 设置验证码'abc':\n",
    "manager.start() # 启动Queue:\n",
    "\n",
    "# 获得通过网络访问的Queue对象:\n",
    "task = manager.get_task_queue()\n",
    "result = manager.get_result_queue()\n",
    "\n",
    "for i in range(10):\n",
    "    n = random.randint(0, 10000)\n",
    "    print('Put task %d...' % n)\n",
    "    task.put(n)\n",
    "    \n",
    "print('Try get results...')\n",
    "\n",
    "for i in range(10):\n",
    "    r = result.get(timeout=10)\n",
    "    print('Result: %s' % r)\n",
    "    \n",
    "manager.shutdown()\n",
    "print('master exit.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。\n",
    "\n",
    "然后，在另一台机器上启动任务进程（本机上启动也可以）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_worker.py\n",
    "\n",
    "import sys, time, queue\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "# 创建类似的QueueManager:\n",
    "class QueueManager(BaseManager):\n",
    "    pass\n",
    "\n",
    "# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:\n",
    "QueueManager.register('get_task_queue')\n",
    "QueueManager.register('get_result_queue')\n",
    "\n",
    "# 连接到服务器，也就是运行task_master.py的机器:\n",
    "server_addr = '127.0.0.1'\n",
    "print('Connect to server %s...' % server_addr)\n",
    "\n",
    "# 端口和验证码注意保持与task_master.py设置的完全一致:\n",
    "m = QueueManager(address=(server_addr, 5000), authkey=b'abc')\n",
    "m.connect() # 从网络连接:\n",
    "\n",
    "# 获取Queue的对象:\n",
    "task = m.get_task_queue() \n",
    "result = m.get_result_queue()\n",
    "\n",
    "# 从task队列取任务,并把结果写入result队列:\n",
    "for i in range(10):\n",
    "    try:\n",
    "        n = task.get(timeout=1)\n",
    "        print('run task %d * %d...' %(n, n))\n",
    "        r = '%d * %d = %d' % (n, n, n*n)\n",
    "        time.sleep(1)\n",
    "        result.put(r)\n",
    "    except Queue.Empty:\n",
    "        print('task queue is empty')\n",
    "# 处理结束:\n",
    "print('worker exit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
